{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFUS3Ol7IVWIWmxkawU/Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashraqat03/Mini-Drug-Repurposing-Agent-Planner-Executor-Workflow-using-LangGraph/blob/main/Drug_repurposing_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing individual parts"
      ],
      "metadata": {
        "id": "cPVbXv8EbPxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m3O5r2iW5U9",
        "outputId": "9a1e54d1-d5a8-4517-8c67-58e77621525c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found targets: [{'gene_symbol': 'LRRK2', 'disease_name': \"Parkinson's disease\", 'association_score': 0.95}, {'gene_symbol': 'SNCA', 'disease_name': \"Parkinson's disease\", 'association_score': 0.89}, {'gene_symbol': 'PINK1', 'disease_name': \"Parkinson's disease\", 'association_score': 0.87}]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the data\n",
        "gene_disease_df = pd.read_csv('gene_disease.csv')\n",
        "\n",
        "def find_targets(disease_query):\n",
        "    # Simple filtering: find rows where disease_name matches the query\n",
        "    results_df = gene_disease_df[gene_disease_df['disease_name'] == disease_query]\n",
        "    # Convert the result to a list of dictionaries for easy use\n",
        "    results_list = results_df.to_dict('records')\n",
        "    return results_list\n",
        "\n",
        "targets = find_targets(\"Parkinson's disease\")\n",
        "print(\"Found targets:\", targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_target_df = pd.read_csv('drug_target.csv')\n",
        "\n",
        "def find_compounds(target_genes_list):\n",
        "    # Filter the dataframe: find rows where 'target_gene' is IN the list provided\n",
        "    results_df = drug_target_df[drug_target_df['target_gene'].isin(target_genes_list)]\n",
        "    return results_df.to_dict('records')\n",
        "\n",
        "compounds = find_compounds([\"LRRK2\", \"SNCA\"])\n",
        "print(\"Found compounds:\", compounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayjKZHkSbr2n",
        "outputId": "89fc5fc5-a700-4726-90d4-cd5e92607266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found compounds: [{'drug_name': 'Rapamycin', 'target_gene': 'LRRK2', 'mechanism': 'inhibitor'}, {'drug_name': 'Nilotinib', 'target_gene': 'SNCA', 'mechanism': 'inhibitor'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROJECT TRIAL 1"
      ],
      "metadata": {
        "id": "wW4aHHaABHYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph langchain-google-genai google-generativeai pandas scikit-learn requests streamlit"
      ],
      "metadata": {
        "id": "jsKPce7T2yfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import re"
      ],
      "metadata": {
        "id": "8mjpYCvRB8sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The librarian (finder)"
      ],
      "metadata": {
        "id": "quHD0oAPXRH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_targets(disease_name):\n",
        "    \"\"\"\n",
        "    Looks up a disease in the gene_disease.csv file and returns associated targets.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv('gene_disease.csv')\n",
        "        results_df = df[df['disease_name'].str.contains(disease_name, case=False, na=False)]\n",
        "\n",
        "        if results_df.empty:\n",
        "            return {\"error\": f\"No targets found for disease: '{disease_name}'.\"}\n",
        "\n",
        "        return {\"targets\": results_df.sort_values('association_score', ascending=False).to_dict('records')}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Failed to read gene-disease data: {str(e)}\"}\n",
        "\n",
        "test_result = find_targets(\"Parkinson's\")\n",
        "\n",
        "print(\"Test find_targets result:\", test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek-c4HVPEdf6",
        "outputId": "76d17da6-e1cb-4753-b7e2-0d09868aa049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test find_targets result: {'targets': [{'gene_symbol': 'LRRK2', 'disease_name': \"Parkinson's disease\", 'association_score': 0.95}, {'gene_symbol': 'SNCA', 'disease_name': \"Parkinson's disease\", 'association_score': 0.89}, {'gene_symbol': 'PINK1', 'disease_name': \"Parkinson's disease\", 'association_score': 0.87}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pharmacist"
      ],
      "metadata": {
        "id": "xR0A12KKXVN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_compounds(target_genes):\n",
        "  \"\"\"\"\n",
        "  Looks up one or more target genes in the drug_target.csv file and returns associated compounds.\n",
        "  kinda the pharmacist.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    df_data = pd.read_csv('drug_target.csv')\n",
        "    if isinstance(target_genes,str):\n",
        "      target_genes = [target_genes]\n",
        "\n",
        "    results_df = df_data[df_data['target_gene'].isin(target_genes)]\n",
        "\n",
        "    if results_df.empty:\n",
        "      return {\"error\": f\"No compounds found for target genes: {target_genes}\"}\n",
        "\n",
        "    # Merge with compounds_df_corrected to get SMILES\n",
        "    compounds_with_smiles = results_df.merge(compounds_df_corrected[['compound_id', 'SMILES']],\n",
        "                                              left_on='drug_name',\n",
        "                                              right_on='compound_id',\n",
        "                                              how='left')\n",
        "    # Drop the redundant 'compound_id' column\n",
        "    compounds_with_smiles = compounds_with_smiles.drop('compound_id', axis=1)\n",
        "\n",
        "    results_list=compounds_with_smiles.to_dict('records')\n",
        "    return {\"compounds\": results_list}\n",
        "\n",
        "  except Exception as e:\n",
        "    return {\"error\": f\"Failed to read drug-target data: {str(e)}\"}\n",
        "\n",
        "#TESTINGG\n",
        "#CASE 1\n",
        "print(\"test1: list input:\", find_compounds([\"LRRK2\",\"SNCA\"]))\n",
        "\n",
        "#CASE 2\n",
        "print(\"test2: string input:\", find_compounds(\"EGFR\"))\n",
        "\n",
        "#CASE 3 (check bs en el exceptions are working)\n",
        "print(\"test3: error test:\", find_compounds(\"blablabla\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9WqJ3D1UlF0",
        "outputId": "03a8a09a-f212-4c42-c268-a2afaa4150bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test1: list input: {'compounds': [{'drug_name': 'Rapamycin', 'target_gene': 'LRRK2', 'mechanism': 'inhibitor', 'SMILES': 'C1CCCCC1'}, {'drug_name': 'Nilotinib', 'target_gene': 'SNCA', 'mechanism': 'inhibitor', 'SMILES': 'CC1=CC=CC(=C1)NC(=O)C2=CN=C3N2C=CC(=C3)NC(=O)C4=CC=C(C=C4)N5CCN(CC5)C'}]}\n",
            "test2: string input: {'compounds': [{'drug_name': 'Gefitinib', 'target_gene': 'EGFR', 'mechanism': 'inhibitor', 'SMILES': 'COC1=CC2=C(C=C1OCCCN3CCOCC3)N=CN=C2NC4=CC=C(C=C4)Cl'}, {'drug_name': 'Erlotinib', 'target_gene': 'EGFR', 'mechanism': 'inhibitor', 'SMILES': 'COC1=CC2=C(C=C1OC)N=CN=C2NC3=CC=C(C=C3)OCCOC'}]}\n",
            "test3: error test: {'error': \"No compounds found for target genes: ['blablabla']\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QSAR trial"
      ],
      "metadata": {
        "id": "42LljMTZXa4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "T341zGOOZDW9",
        "outputId": "a27813b7-f064-4658-8c5d-18ca28126c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numpy (from rdkit)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow (from rdkit)\n",
            "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow, numpy, rdkit\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-11.3.0 numpy-2.3.3 rdkit-2025.3.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "04e3fbc2b791445c8fab5b0d9d3bef88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BxWjKbz7XafA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptor_list = [\n",
        "    'MolWt',\n",
        "    'MolLogP',\n",
        "    'NumHDonors',\n",
        "    'NumHAcceptors',\n",
        "    'NumRotatableBonds',\n",
        "    'TPSA', # Topological Polar Surface Area (critical for permeability)\n",
        "    'HeavyAtomCount',\n",
        "    'RingCount',\n",
        "    'FractionCSP3' # Measures carbon saturation (related to compound quality)\n",
        "]"
      ],
      "metadata": {
        "id": "4Z06omOClZdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compounds_data_corrected = {\n",
        "    'compound_id': ['Rapamycin', 'Nilotinib', 'Gefitinib', 'Erlotinib', 'Olaparib', 'Trametinib', 'Metformin', 'Aspirin', 'Ibuprofen'],\n",
        "    'SMILES': [\n",
        "        'C1CCCCC1', # Simple cyclohexane stand-in for Rapamycin\n",
        "        'CC1=CC=CC(=C1)NC(=O)C2=CN=C3N2C=CC(=C3)NC(=O)C4=CC=C(C=C4)N5CCN(CC5)C', # Valid Nilotinib\n",
        "        'COC1=CC2=C(C=C1OCCCN3CCOCC3)N=CN=C2NC4=CC=C(C=C4)Cl', # Valid Gefitinib\n",
        "        'COC1=CC2=C(C=C1OC)N=CN=C2NC3=CC=C(C=C3)OCCOC', # Valid Erlotinib\n",
        "        'O=C(C1CCCCN1)NC2=CC=CC3=C2N=CN=C3N4CCOCC4', # Valid Olaparib\n",
        "        'CNC(=O)C1=CC2=C(C=C1C3=CC=CC=C3)S(=O)(=O)C4=CC=C(C=C4)N5CCN(CCO)CC5', # Valid Trametinib\n",
        "        'CN(C)C(=N)N=C(N)N', # Metformin\n",
        "        'CC(=O)OC1=CC=CC=C1C(=O)O', # Aspirin\n",
        "        'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O' # Ibuprofen\n",
        "    ],\n",
        "    'activity_label': [1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
        "}\n",
        "compounds_df_corrected = pd.DataFrame(compounds_data_corrected)\n",
        "compounds_df_corrected.to_csv('compounds.csv', index=False)\n",
        "print(\"Created NEW compounds.csv with VALID SMILES strings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIleiQ3A9urq",
        "outputId": "07d99c75-47df-437f-c4ec-be62978fea52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created NEW compounds.csv with VALID SMILES strings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_list)\n",
        "\n",
        "def compute_descriptors(smiles):\n",
        "    \"\"\"\n",
        "    Calculates a set of 9 key physicochemical properties for a molecule.\n",
        "    \"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    descriptors = calculator.CalcDescriptors(mol)\n",
        "    return np.array(descriptors)\n"
      ],
      "metadata": {
        "id": "JlHDANRYldNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_qsar_model():\n",
        "  \"\"\"\n",
        "  using logistic regression to predict compound activity based on molecular features.\n",
        "  use the compounds.csv file to train the model.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    qsar_df= pd.read_csv(\"compounds.csv\")\n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    for index, row in qsar_df.iterrows():\n",
        "      smiles= row['SMILES']\n",
        "      label= row['activity_label']\n",
        "\n",
        "      mol=Chem.MolFromSmiles(smiles)\n",
        "      desc_vector = compute_descriptors(smiles)\n",
        "      if desc_vector is not None:\n",
        "                X.append(desc_vector)\n",
        "                y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "        # Save the scaler\n",
        "    joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "    model=LogisticRegression(random_state=42, class_weight='balanced')\n",
        "    model.fit(X_scaled,y)\n",
        "    joblib.dump(model, 'qsar_model.joblib')\n",
        "    print({\"message\": f\"Model trained successfully on {X.shape[0]} molecules with {X.shape[1]}.\"})\n",
        "\n",
        "  except Exception as e:\n",
        "    print({f\"error: Failed to train QSAR model: {str(e)}\"})"
      ],
      "metadata": {
        "id": "lccDnm_OZvxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_activity(smiles_list):\n",
        "    \"\"\"\n",
        "    Predicts activity.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = joblib.load('qsar_model.joblib')\n",
        "        scaler = joblib.load('scaler.joblib')\n",
        "        predictions = []\n",
        "        for smiles in smiles_list:\n",
        "            desc_vector = compute_descriptors(smiles)\n",
        "            if desc_vector is not None:\n",
        "                desc_vector_scaled = scaler.transform(desc_vector.reshape(1, -1))\n",
        "                proba = model.predict_proba(desc_vector_scaled)[0][1]\n",
        "                predictions.append(float(round(proba, 2)))\n",
        "            else:\n",
        "                # Handle invalid SMILES by appending a default value and printing a warning\n",
        "                print(f\"Warning: Could not parse SMILES '{smiles}'. Setting probability to 0.\")\n",
        "                predictions.append(0.0)\n",
        "        return {\"predictions\": predictions}\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Prediction failed: {str(e)}\"}"
      ],
      "metadata": {
        "id": "WIwK2GjZ47zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_qsar_model()\n",
        "\n",
        "test_smiles_inactive = [\"CN(C)C(=N)N=C(N)N\", \"CC(=O)OC1=CC=CC=C1C(=O)O\"]\n",
        "test_smiles_active = [\"CC1=CC=CC(=C1)NC(=O)C2=CN=C3N2C=CC(=C3)NC(=O)C4=CC=C(C=C4)N5CCN(CC5)C\"]\n",
        "\n",
        "print(\"Test Inactive Compounds:\", predict_activity(test_smiles_inactive))\n",
        "print(\"Test Active Compound:\", predict_activity(test_smiles_active))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_XtHCp78mE",
        "outputId": "6a7779d3-3287-422b-efa8-2e711aac87bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'message': 'Model trained successfully on 8 molecules with 9.'}\n",
            "Test Inactive Compounds: {'predictions': [0.05, 0.14]}\n",
            "Test Active Compound: {'predictions': [0.9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[18:48:24] SMILES Parse Error: unclosed ring for input: 'CNC(=O)C1=CC2=C(C=C1C3=CC=CC=C3)S(=O)(=O)C4=CC=C(C=C4)N5CCN(CCO)CC5'\n",
            "[18:48:24] SMILES Parse Error: unclosed ring for input: 'CNC(=O)C1=CC2=C(C=C1C3=CC=CC=C3)S(=O)(=O)C4=CC=C(C=C4)N5CCN(CCO)CC5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integrating Gemeni**"
      ],
      "metadata": {
        "id": "xunlg-jp6flM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=userdata.get('API')\n",
        ")"
      ],
      "metadata": {
        "id": "1u_gvVoS2LiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Planner Node"
      ],
      "metadata": {
        "id": "L6sNHSl4AB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DEFINE THE PLANNER NODE ---\n",
        "def planner_node(state):\n",
        "    \"\"\"\n",
        "    This is the Planner Agent. It uses the Gemini LLM to analyze the user input\n",
        "    and decide the first step in the workflow.\n",
        "    It returns a decision that LangGraph will use to route the workflow.\n",
        "    \"\"\"\n",
        "    print(f\"Planner analyzing input: '{state['input']}'\")\n",
        "\n",
        "    # The system prompt\n",
        "    planner_prompt = \"\"\"\n",
        "    You are an expert planner for a drug discovery AI. Your only task is to analyze the user's input and decide the first step.\n",
        "\n",
        "    The rules are strict:\n",
        "    1. If the user asks about a *disease* (e.g., \"Parkinson's\", \"cancer\", \"Alzheimer's\"), output: 'find_targets'\n",
        "    2. If the user asks about a *protein*, *gene*, or *target* (e.g., \"EGFR\", \"BRCA1\", \"LRRK2\"), output: 'find_compounds'\n",
        "    3. If you are unsure, output 'find_targets'\n",
        "\n",
        "    Do not output anything else. No explanations. Just one word: either 'find_targets' or 'find_compounds'.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the message for the LLM\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": planner_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"User input: {state['input']}\"}\n",
        "    ]\n",
        "\n",
        "    # Call the Gemini API\n",
        "    response = llm.invoke(messages)\n",
        "    decision = response.content.strip().lower()\n",
        "\n",
        "    print(f\"Planner decision: '{decision}'\")\n",
        "\n",
        "    # Return the decision to the LangGraph state\n",
        "    return {\"next_step\": decision}\n",
        "\n",
        "# TESTING\n",
        "# W/out full graph\n",
        "test_state = {\"input\": \"Parkinson's disease\"}\n",
        "result = planner_node(test_state)\n",
        "print(\"Test Planner Output:\", result)\n",
        "\n",
        "test_state2 = {\"input\": \"EGFR\"}\n",
        "result2 = planner_node(test_state2)\n",
        "print(\"Test Planner Output 2:\", result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OChlE2rF6lan",
        "outputId": "baf9a21a-69c1-44ef-bf2e-43e241aafa9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Planner analyzing input: 'Parkinson's disease'\n",
            "Planner decision: 'find_targets'\n",
            "Test Planner Output: {'next_step': 'find_targets'}\n",
            "Planner analyzing input: 'EGFR'\n",
            "Planner decision: 'find_compounds'\n",
            "Test Planner Output 2: {'next_step': 'find_compounds'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain"
      ],
      "metadata": {
        "id": "4BHRu_ZbHqZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Annotated\n",
        "import operator"
      ],
      "metadata": {
        "id": "bdKsWyCSHqz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the structure\n",
        "class AgentState(TypedDict):\n",
        "    # The user's original query(no change)\n",
        "    input: str\n",
        "\n",
        "    # The decision from Planner node - will determine our path\n",
        "    next_step: str\n",
        "\n",
        "    # Results from find_targets node - starts as None\n",
        "    targets: List[dict]\n",
        "\n",
        "    # Results from find_compounds node - starts as None\n",
        "    compounds: List[dict]\n",
        "\n",
        "    # Results from predict_activity node - starts as None\n",
        "    predictions: List[dict]\n",
        "\n",
        "    # Final report - will be added at the very end\n",
        "    report: str"
      ],
      "metadata": {
        "id": "C6WGmKGEH0Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# workflow graph\n",
        "workflow = StateGraph(AgentState)\n",
        "print(\"initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWxDM1MGIQ0w",
        "outputId": "60dd4ca3-94f5-4faf-990e-b62d8e69053a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find_targets\n",
        "def find_targets_node(state):\n",
        "    \"\"\"Node version of our find_targets tool\"\"\"\n",
        "    print(\"Librarian finding targets...\")\n",
        "    result = find_targets(state['input'])  # Use input from state\n",
        "    if \"error\" in result:\n",
        "        return {\"error\": result[\"error\"]}\n",
        "    return {\"targets\": result[\"targets\"]}  # Update state with targets\n",
        "\n",
        "# find_compounds Node\n",
        "def find_compounds_node(state):\n",
        "    \"\"\"Node version of our find_compounds tool\"\"\"\n",
        "    print(\"Pharmacist finding compounds...\")\n",
        "    # Get targets from state or use input directly\n",
        "    if state.get('targets'):\n",
        "        target_genes = [t['gene_symbol'] for t in state['targets']]\n",
        "    else:\n",
        "        target_genes = [state['input']]  # Input was probably a gene\n",
        "\n",
        "    result = find_compounds(target_genes)\n",
        "    if \"error\" in result:\n",
        "        return {\"error\": result[\"error\"]}\n",
        "    return {\"compounds\": result[\"compounds\"]}  # Update state with compounds\n",
        "\n",
        "# predict_activity Node\n",
        "def predict_activity_node(state):\n",
        "    \"\"\"Node version of our predict_activity tool\"\"\"\n",
        "    print(\"Chemist predicting activity...\")\n",
        "    smiles_list = [c['SMILES'] for c in state['compounds']]\n",
        "    result = predict_activity(smiles_list)\n",
        "    if \"error\" in result:\n",
        "        return {\"error\": result[\"error\"]}\n",
        "    return {\"predictions\": result[\"predictions\"]}  # Update state with predictions\n",
        "\n",
        "print(\"All node functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgrOUElyIazd",
        "outputId": "dbab98c9-b3f6-46d8-9c6e-8e2fb2477fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All node functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add all nodes\n",
        "workflow.add_node(\"planner\", planner_node)\n",
        "workflow.add_node(\"find_targets\", find_targets_node)\n",
        "workflow.add_node(\"find_compounds\", find_compounds_node)\n",
        "workflow.add_node(\"predict_activity\", predict_activity_node)\n",
        "\n",
        "print(\"All nodes added to graph\")\n",
        "print(\"Current nodes:\", workflow.nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edBBDNSMI1Fx",
        "outputId": "41346692-1066-4f21-c7a8-629975f1ce07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All nodes added to graph\n",
            "Current nodes: {'planner': StateNodeSpec(runnable=planner(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.AgentState'>, retry_policy=None, cache_policy=None, ends=(), defer=False), 'find_targets': StateNodeSpec(runnable=find_targets(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.AgentState'>, retry_policy=None, cache_policy=None, ends=(), defer=False), 'find_compounds': StateNodeSpec(runnable=find_compounds(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.AgentState'>, retry_policy=None, cache_policy=None, ends=(), defer=False), 'predict_activity': StateNodeSpec(runnable=predict_activity(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.AgentState'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_next_step(state):\n",
        "    \"\"\"Reads the planner's decision and routes accordingly\"\"\"\n",
        "    next_step = state['next_step']\n",
        "    print(f\"Routing to: {next_step}\")\n",
        "    return next_step\n",
        "\n",
        "# Set the starting point\n",
        "workflow.set_entry_point(\"planner\")\n",
        "\n",
        "# Add conditional routing after planner\n",
        "workflow.add_conditional_edges(\n",
        "    \"planner\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"find_targets\": \"find_targets\",\n",
        "        \"find_compounds\": \"find_compounds\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_z__weAxI-nZ",
        "outputId": "eb992e06-48f8-41e6-a19a-8a735e229c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Branch with name `decide_next_step` already exists for node `planner`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3781183294.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Add conditional routing after planner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m workflow.add_conditional_edges(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"planner\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdecide_next_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36madd_conditional_edges\u001b[0;34m(self, source, path, path_map)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# validate the condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    645\u001b[0m                 \u001b[0;34mf\"Branch with name `{path.name}` already exists for node `{source}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Branch with name `decide_next_step` already exists for node `planner`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the nodes in sequence\n",
        "workflow.add_edge(\"find_targets\", \"find_compounds\")\n",
        "workflow.add_edge(\"find_compounds\", \"predict_activity\")\n",
        "workflow.add_edge(\"predict_activity\", END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2jir4fnLcUF",
        "outputId": "ef6425b5-cf01-4741-bd6c-3d6fcc4131a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x785d68447710>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "Bd-NCCjeLkcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the complete workflow!\n",
        "print(\"Testing complete workflow for Parkinson's disease...\")\n",
        "result = app.invoke({\"input\": \"Parkinson's disease\"})\n",
        "print(\"\\n=== FINAL RESULTS ===\")\n",
        "print(\"Targets found:\", len(result['targets']))\n",
        "print(\"Compounds found:\", len(result['compounds']))\n",
        "print(\"Predictions made:\", len(result['predictions']))\n",
        "print(\"\\nSample prediction:\", result['predictions'][0] if result['predictions'] else \"None\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvUQv-vbLoyT",
        "outputId": "5c834089-0f66-47fa-c4f9-f482f980f676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing complete workflow for Parkinson's disease...\n",
            "Planner analyzing input: 'Parkinson's disease'\n",
            "Planner decision: 'find_targets'\n",
            "üîÑ Routing to: find_targets\n",
            "Librarian finding targets...\n",
            "Pharmacist finding compounds...\n",
            "Chemist predicting activity...\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "Targets found: 3\n",
            "Compounds found: 2\n",
            "Predictions made: 2\n",
            "\n",
            "Sample prediction: 0.61\n"
          ]
        }
      ]
    }
  ]
}